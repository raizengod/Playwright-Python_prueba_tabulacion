# Proyecto de AutomatizaciÃ³n de Pruebas UI y rendimiento bÃ¡sico con Playwright y Python ğŸ§ª

## ğŸš€ DescripciÃ³n General
Este proyecto es un framework de automatizaciÃ³n de pruebas de interfaz de usuario (UI) robusto y escalable, desarrollado con Playwright y Python, utilizando Pytest como gestor de pruebas. 
Este repositorio contiene un proyecto bÃ¡sico en Python que utiliza la herramienta [Playwright](https://playwright.dev/python/) para realizar pruebas automatizadas de rendimiento en aplicaciones web.

## âœ¨ CaracterÃ­sticas Principales
El framework incluye una serie de funcionalidades diseÃ±adas para optimizar y enriquecer el proceso de automatizaciÃ³n:

* **TecnologÃ­a Moderna:** Implementado con Playwright, un framework rÃ¡pido y confiable para la automatizaciÃ³n de navegadores.
* **Lenguaje de ProgramaciÃ³n:** Desarrollado en Python 3.13.5 (versiÃ³n recomendada, aunque puede ser compatible con otras versiones de Python 3).
* **GestiÃ³n de Pruebas:** OrganizaciÃ³n y ejecuciÃ³n de casos de prueba con Pytest, aprovechando su sistema de fixtures.
* **Cross-Browser & Responsive Testing:** Soporte para pruebas en Chromium, Firefox y WebKit, incluyendo emulaciÃ³n de dispositivos mÃ³viles como iPhone 12 y Pixel 5 para asegurar la compatibilidad y el comportamiento responsivo.
* **Manejo de Elementos y Interacciones:** Funciones globales para:
    * VerificaciÃ³n contenido de una tabla
    * Relleno de campos de texto y numÃ©ricos.
    * InteracciÃ³n con iframes y nuevas ventanas/pestaÃ±as.
    * ValidaciÃ³n de tÃ­tulos de pÃ¡gina.
* **GestiÃ³n de Archivos:** Capacidades para lectura de diversos formatos de datos:
    * Excel (.xlsx)
    * CSV (.csv)
    * JSON (.json)
    * XML
* **GeneraciÃ³n de Evidencias:** Capturas de pantalla automÃ¡ticas en puntos crÃ­ticos y rutas configurables para almacenamiento de videos y trazas de ejecuciÃ³n.
* **Logging Configurable:** Sistema de logging detallado con niveles de salida separados para consola y archivo, facilitando la depuraciÃ³n y el seguimiento de la ejecuciÃ³n.
* **OrganizaciÃ³n del CÃ³digo:** Estructura de proyecto modular que separa locators, pÃ¡ginas y utilidades, promoviendo la reusabilidad y mantenibilidad.
* **Pruebas de Rendimiento BÃ¡sicas:**
    * **MediciÃ³n de Tiempos de Carga:** Se han integrado mediciones de tiempo de principio a fin para acciones especÃ­ficas como Drag and Drop.
    * **Logging de Rendimiento:** Los tiempos de ejecuciÃ³n de operaciones crÃ­ticas se registran en los logs para su posterior anÃ¡lisis.

## ğŸ› ï¸ TecnologÃ­as Utilizadas
* **Playwright:** Framework de automatizaciÃ³n de navegadores.
* **Python:** Lenguaje de programaciÃ³n.
* **Pytest:** Framework para la gestiÃ³n y ejecuciÃ³n de pruebas.
* **pytest-html:** Para la generaciÃ³n de informes HTML autocontenidos.
* **Openpyxl:** LibrerÃ­a para manejar archivos .xlsx.
* **CSV:** MÃ³dulo para trabajar con archivos .csv.
* **JSON:** MÃ³dulo para manejar archivos JSON.
* **xml.etree.ElementTree:** MÃ³dulo para trabajar con archivos XML.
* **Logging:** MÃ³dulo estÃ¡ndar de Python para el registro de eventos.

## ğŸ“‚ Estructura del Proyecto
La estructura del proyecto estÃ¡ diseÃ±ada para ser clara, modular y fÃ¡cil de mantener:
```
.
â”œâ”€â”€ Perform/
â”‚   â”œâ”€â”€ pages/                   # Clases con las funciones de las pÃ¡ginas (lÃ³gica)
â”‚   â”‚   â”œâ”€â”€ base_page.py
â”‚   â”œâ”€â”€ locator/                 # Clases con los selectores de los elementos
â”‚   â”‚   â”œâ”€â”€ locator_barraNavegacion.py
â”‚   â”‚   â””â”€â”€ locator_ModalDataTable.py
â”‚   â”œâ”€â”€ utils/                   # MÃ³dulos de utilidad
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ archivos/               # Archivos de prueba (ej. para upload/download)
â”‚   â”‚   â””â”€â”€ archivos_data_fuente/
â”‚   â”œâ”€â”€ reportes/               # Directorio para almacenar evidencias de las pruebas
â”‚   â”‚   â”œâ”€â”€ html/               # Informes HTML
â”‚   â”‚   â”œâ”€â”€ video/              # Grabaciones de video de las ejecuciones
â”‚   â”‚   â”œâ”€â”€ traceview/          # Archivos traceview de Playwright
â”‚   â”‚   â””â”€â”€ imagen/             # Capturas de pantalla
â”‚   â”œâ”€â”€ conftest.py              # Fixtures de Pytest para configuraciones globales
â”‚   â””â”€â”€ test_ModalDataTable.py   # Archivos de pruebas
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â””â”€â”€ README.md
```

## âš™ï¸ ConfiguraciÃ³n e InstalaciÃ³n
**Clonar el repositorio:**

```bash
git clone https://github.com/raizengod/Playwright-Python_prueba_rendiemiento_basico.git
cd Rendimiento
```

**Crear y activar un entorno virtual (recomendado):**

```bash
python -m venv mv_Rendimiento
.\venv\Scripts\activate
# En Windows
```

```bash
python -m venv mv_Rendimiento
source venv/bin/activate
# En macOS/Linux
```

**Instalar las dependencias:**

```bash
pip install -r requirements.txt
playwright install  # Instala los navegadores necesarios (Chromium, Firefox, WebKit)
# (AsegÃºrate de que pytest-reporter-html1 estÃ© incluido en requirements.txt)
```

```bash
pip install playwright pytest pytest-html openpyxl
playwright install
```

Asegurar Directorios de Evidencias: El archivo config.py define una funciÃ³n ensure_directories_exist() que crea automÃ¡ticamente las carpetas necesarias para reportes y archivos de datos. AsegÃºrate de que esta funciÃ³n se ejecute, o crÃ©alas manualmente segÃºn la Estructura del Proyecto.

## ğŸš€ Uso
Para ejecutar las pruebas, asegÃºrate de estar en el entorno virtual activado y en la raÃ­z del proyecto.

**EjecuciÃ³n de Pruebas**

1.  **Ejecuta las pruebas y genera los resultados de reporte:**
    ```bash
    pytest Perform\test\test_ModalDataTable.py -s -v --template=html1/index.html --report=reportes/html1/playwright_reporte.html
    ```

2.  **Ejecutar todas las pruebas con Pytest:**
    ```bash
    pytest Perform\test\
    ```

3.  **Ejecutar pruebas especÃ­ficas (ejemplo):**
    ```bash
    pytest Perform\test\test_ModalDataTable.py
    ```

4.  **Ejecutar todas las pruebas con reporte detallado y genera los resultados en reporte HTML:**:**
    ```bash
    pytest Perform\test\ -s -v --template=html1/index.html --report=reportes/html1/playwright_reporte.html
    ```

5.  **Ejecuta las pruebas en paralelo y genera los resultados de reporte:**
    ```bash
    pytest Perform\test\ -s -v -n 5 --template=html1/index.html --report=reportes/html1/playwright_reporte.html
    ```

## ğŸ“Š IntegraciÃ³n de Pruebas de Rendimiento
El framework ha sido mejorado para incluir la mediciÃ³n del rendimiento en operaciones crÃ­ticas. En la clase Funciones_Globales (en base_page.py), se han aÃ±adido puntos de mediciÃ³n que registran el tiempo de ejecuciÃ³n de acciones complejas como "Drag and Drop manual" y los escriben en el log.

**Ejemplo de Salida de Log**
```bash
# Ejemplo para la operaciÃ³n de rellenado de texto
INFO - Rellenando campo con selector '#username' con el texto: 'usuario_demo'.
...
INFO - PERFORMANCE: Tiempo que tardÃ³ en rellenar el campo '#username': 0.0567 segundos.
...
INFO - âœ” Ã‰XITO: Campo '#username' rellenado con Ã©xito con el texto: 'usuario_demo'.
```
Estas mediciones permiten a los QA y desarrolladores identificar cuellos de botella y regresiones de rendimiento a medida que el proyecto evoluciona.

## ğŸ“ˆ Reportes y Evidencias

Todas las evidencias generadas durante la ejecuciÃ³n de las pruebas se almacenarÃ¡n en el directorio test/reportes/:
* test/reportes/html/: Contiene los informes HTML de Pytest.
* test/reportes/video/: Videos de la ejecuciÃ³n de las pruebas (si estÃ¡n configurados en conftest.py).
* test/reportes/traceview/: Archivos de traza de Playwright para anÃ¡lisis detallado.
* test/reportes/imagen/: Capturas de pantalla tomadas durante la ejecuciÃ³n.

## ğŸ“ˆ IntegraciÃ³n Continua (CI)

El proyecto estÃ¡ configurado con **GitHub Actions** para ejecutar las pruebas automÃ¡ticamente en cada push a la rama principal y en cada pull request. El archivo de configuraciÃ³n se encuentra en `.github/workflows/playwright.yml`. Esto garantiza que cualquier cambio en el cÃ³digo se valide rÃ¡pidamente, detectando regresiones de manera temprana.

## âœ… Habilidades Demostradas

A travÃ©s de este proyecto, demuestro las siguientes habilidades clave en QA Automation:

* **DiseÃ±o de Frameworks de AutomatizaciÃ³n:** ImplementaciÃ³n de una estructura de proyecto modular y escalable utilizando el patrÃ³n Page Object Model (POM).
* **AutomatizaciÃ³n de Pruebas End-to-End:** CreaciÃ³n de escenarios de prueba realistas que cubren flujos de usuario completos.
* **Uso Avanzado de Playwright:** Experiencia profunda en la interacciÃ³n con elementos web, manejo de aserciones robustas, gestiÃ³n de contextos de navegador, emulaciÃ³n de dispositivos y configuraciÃ³n de pruebas con Playwright.
* **ProgramaciÃ³n en Python:** Habilidad para escribir cÃ³digo limpio, legible y eficiente para la automatizaciÃ³n, aplicando principios de diseÃ±o de software.
* **IntegraciÃ³n Continua (CI):** ConfiguraciÃ³n y mantenimiento de pipelines de CI con GitHub Actions para una ejecuciÃ³n de pruebas automatizada y recurrente, esencial en el ciclo de vida del desarrollo de software.
* **IdentificaciÃ³n y Reporte de Bugs:** Capacidad para diseÃ±ar pruebas que revelen defectos y, en un entorno de trabajo real, reportarlos adecuadamente con evidencia relevante.
* **Mantenibilidad de CÃ³digo:** OrganizaciÃ³n del cÃ³digo para facilitar futuras actualizaciones y extensiones de las pruebas, promoviendo la colaboraciÃ³n y escalabilidad a largo plazo.
* **Manejo de Datos en Pruebas:** Experiencia en la lectura y escritura de datos de prueba desde/hacia archivos Excel, CSV, JSON y XML.

# ğŸ”® Mejoras Futuras / Roadmap

Este proyecto es una base sÃ³lida, y siempre hay espacio para la mejora continua. Algunas ideas para futuras extensiones incluyen:

* Configurar variables de entorno para la URL base y credenciales, mejorando la seguridad y flexibilidad del framework.
* Extender la cobertura con pruebas de APIs para una validaciÃ³n completa del backend (si aplica).

## Licencia

Este proyecto no tiene una licencia especÃ­fica declarada. Consulta con el autor para su uso en producciÃ³n.

## Autor

[Carlos N](https://github.com/raizengod)